# Story 6.1: Extended Dataset Ingestion Integrity

## Status

Draft

## Story

**As a** data engineer,  
**I want** the extended Palmer Penguins dataset ingested accurately,  
**so that** the application can expose new categorical findings without losing data fidelity.

## Acceptance Criteria

1. `Penguin` type includes `diet`, `life_stage`, and `health_metrics` fields with null-safe handling
2. Year range supports 2021–2025 and matches source data
3. Ingestion pipeline retains all extended fields in `public/data/penguins.json`
4. Category normalization maps variants (e.g., `Torgensen` → `Torgersen`) before filters consume data
5. Data assumptions and transformations documented for QA review

## Dependencies

- Completion status of previous epics verified; no upstream blockers identified for data ingestion work.

## Tasks / Subtasks

- [ ] **Task 1: Update Types and Raw Data Contracts** (AC: 1, 2)
  - [ ] Extend `src/types/penguin.ts` interfaces for extended fields while preserving strict typing
  - [ ] Align raw data typings with new year range and categorical unions
  - [ ] Document nullable field handling inline for QA reference
- [ ] **Task 2: Preserve Extended Fields During Transformation** (AC: 1, 3)
  - [ ] Refactor `transformPenguinData` in `src/hooks/usePenguinData.ts` to retain new fields
  - [ ] Ensure null-safe conversions for numeric and categorical additions
  - [ ] Add unit coverage around the transformer for extended attributes
- [ ] **Task 3: Normalize Categorical Variants** (AC: 4)
  - [ ] Create normalization helpers in `src/utils/dataHelpers.ts` or dedicated utility
  - [ ] Map known variants (e.g., `Torgensen`) before state stores consume values
  - [ ] Add guardrails for unexpected categories with logging and tests
- [ ] **Task 4: Update Data Store and Selectors** (AC: 3, 4)
  - [ ] Ensure Zustand data and filter stores expose extended fields without breaking existing consumers
  - [ ] Memoize derived maps to handle 3k+ records without regressions
  - [ ] Verify URL/state synchronization accounts for normalized values
- [ ] **Task 5: Documentation and QA Handoff** (AC: 5)
  - [ ] Record transformation assumptions in project docs (README or QA notes)
  - [ ] Update ingestion-related ADR or architecture references if required
  - [ ] Provide dataset spot-check results to QA team
- [ ] **Task 6: Quality Gates** (AC: 1-5)
  - [ ] Extend unit tests for data helpers and stores
  - [ ] Run existing lint/prettier/test suites locally
  - [ ] Capture before/after performance metrics for ingestion load

## Dev Notes

### Previous Story Insights

- Story 5.2 established URL synchronization via `useURLSync`; extended filters must integrate with the same serialization patterns to keep shared links valid. [Source: .agents/stories/5.2.share-filtered-view.story.md]

### Data Models

- Data and filter stores in Zustand share a central `Penguin` model; any type updates must remain compatible with selectors that compute species/island distributions and numeric ranges. [Source: .agents/architecture/state-management.md#store-architecture]

### Data Flow

- Data loading sequence pulls from `public/data/penguins.json`, hydrates stores, and normalizes filter state via memoized selectors; transformations should occur before store hydration to avoid redundant recomputation. [Source: .agents/architecture/data-flow.md#initial-load-sequence]

### State Management

- The data store handles raw dataset storage, error handling, and computed maps; normalization utilities should feed through `loadData` to preserve caching and selector memoization guarantees. [Source: .agents/architecture/state-management.md#data-store-datastorets]

### File Locations

- Dataset and ingestion logic reside under `public/` and `src/hooks/` respectively; normalization helpers belong in `src/utils/` per project structure guidelines. [Source: .agents/architecture/source-tree.md#project-organization]

### Testing Requirements

- Follow the testing pyramid with Vitest coverage for transformers and helpers, integration checks for store updates, and ensure accessibility/performance budgets remain intact. [Source: .agents/architecture/testing-strategy.md#pyramid-distribution]

### Technical Constraints

- Performance budgets require filter interactions <100 ms and chart renders <300 ms; memoization and normalization must scale for ~3k records without breaching these targets. [Source: .agents/architecture/performance.md#performance-requirements]

### Project Structure Notes

- Maintain existing directory conventions and avoid introducing new top-level folders; reuse `utils/dataHelpers.ts` or create adjacent helpers to keep data processing centralized. [Source: .agents/architecture/source-tree.md#utility-organization]

## Project Structure Alignment

- No structural conflicts identified; planned updates align with established hooks, utils, and types locations documented in the architecture.

## Risks / Open Questions

- Confirm availability of authoritative mapping for categorical variants beyond `Torgensen`; document any assumptions for QA sign-off.

## Testing

### Testing Standards

- Follow Vitest-based unit coverage for transformers and helpers with files under `tests/unit/utils/` and `tests/unit/hooks/`. [Source: .agents/architecture/testing-strategy.md#file-locations]
- Add integration verification for store updates within `tests/integration/filters/` or equivalent suites to confirm normalized data flows. [Source: .agents/architecture/testing-strategy.md#pyramid-distribution]
- Ensure accessibility/performance automation remains green after ingestion changes by running the existing CI scripts (`npm run style:all`, Cypress smoke where applicable). [Source: .agents/architecture/testing-strategy.md#validation-requirements]

## Change Log

| Date       | Version | Description                                | Author |
| ---------- | ------- | ------------------------------------------ | ------ |
| 2025-10-18 | v0.1    | Initial draft for Story 6.1 (Draft status) | Bob    |

## Dev Agent Record

### Agent Model Used

_To be completed by Dev Agent_

### Debug Log References

_To be completed by Dev Agent_

### Completion Notes

_To be completed by Dev Agent_

### File List

_To be completed by Dev Agent_

## QA Results

_To be completed by QA Agent_
